{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FPGBq3FbJ9UBchjzx2_mpeU5AlMTXDNr",
      "authorship_tag": "ABX9TyOKlv+ZF/OXhsi+/a3Zca1v"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSW_aE2_nxEt",
        "outputId": "d03820db-1847-40d4-97ea-badea5157c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_forecasting in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy<=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (1.26.4)\n",
            "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (2.5.1+cu124)\n",
            "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (2.5.0.post0)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (1.13.1)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (1.6.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2024.10.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (0.12.0)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (24.2)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.6.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (4.12.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.5.0.post0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch_forecasting) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (3.10)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.11/dist-packages (2.5.0.post0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.10.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (1.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_forecasting\n",
        "!pip install pytorch_lightning\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet, NBeats\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_lightning import Trainer\n",
        "import torch\n",
        "import torchmetrics\n",
        "from pytorch_lightning.core.module import LightningModule\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import optuna"
      ],
      "metadata": {
        "id": "HIv7EgkKoiLt"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "def load_data():\n",
        "    df_20_21 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_20_21.csv')\n",
        "    df_21_22 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_21_22.csv')\n",
        "    df_22_23 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_22_23.csv')\n",
        "    df_23_24 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_23_24.csv')\n",
        "    df_24_25 = pd.read_csv('/content/drive/MyDrive/CollabData/Player_Prediction/df_24_25.csv')\n",
        "    return df_20_21,df_21_22,df_22_23, df_23_24, df_24_25"
      ],
      "metadata": {
        "id": "q1VPbbs_qfZR"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data for TFT\n",
        "def preprocess_data_tft(df):\n",
        "    # Add time_idx for temporal ordering\n",
        "    df = df.reset_index()  # Reset index to ensure uniqueness\n",
        "    df['time_idx'] = pd.factorize(df['MP'])[0]\n",
        "\n",
        "    # Feature Engineering\n",
        "    # Fill NaN values in 'Gls' and 'Ast' with 0 before calculating 'G+A'\n",
        "    df['Gls'] = df['Gls'].fillna(0)\n",
        "    df['Ast'] = df['Ast'].fillna(0)\n",
        "    df['G+A'] = df['Gls'] + df['Ast']\n",
        "\n",
        "    df['xG+xAG'] = df['xG'] + df['xAG']\n",
        "\n",
        "    df['Performance_Index'] = (\n",
        "        df['G+A'] * 0.4 +\n",
        "        df['xG+xAG'] * 0.3 +\n",
        "        (df['PrgC'] + df['PrgP'] + df['PrgR']) * 0.2 +\n",
        "        (df['Tkl'] + df['Int'] + df['Blocks']) * 0.1\n",
        "    )\n",
        "\n",
        "    df['Future_Potential'] = (\n",
        "        (1 / (df['Age'] + 1)) * df['MP'] +\n",
        "        df.groupby('Player')['G+A'].transform(lambda x: x.diff().fillna(0))\n",
        "    )\n",
        "\n",
        "    # Verify uniqueness of the index\n",
        "    if not df.index.is_unique:\n",
        "        raise ValueError(\"Data index must be unique.\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "7d3-UQ-KrLB6"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TimeSeriesDataSet\n",
        "def create_tft_dataset(df):\n",
        "    df = preprocess_data_tft(df)\n",
        "\n",
        "    max_prediction_length = 1  # predict one season ahead\n",
        "    max_encoder_length = 3  # use data from the last three seasons\n",
        "\n",
        "    # Calculate the minimum required length\n",
        "    min_data_length = max_encoder_length + max_prediction_length\n",
        "\n",
        "    # Filter out players with insufficient data\n",
        "    df = df.groupby('Player').filter(lambda x: len(x) >= min_data_length)\n",
        "\n",
        "    # Reset index after filtering\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['time_idx'] = pd.factorize(df['MP'])[0]\n",
        "\n",
        "    # Ensure 'Player' column is a string\n",
        "    df['Player'] = df['Player'].astype(str)\n",
        "\n",
        "    training = TimeSeriesDataSet(\n",
        "        df,\n",
        "        time_idx=\"time_idx\",\n",
        "        target=\"G+A\",\n",
        "        group_ids=[\"Player\"],\n",
        "        max_encoder_length=max_encoder_length,\n",
        "        max_prediction_length=max_prediction_length,\n",
        "        static_categoricals=[\"Player\"],  # Only \"Player\" should be categorical\n",
        "        static_reals=[\"Age\"],  # \"Age\" should be treated as numerical\n",
        "        time_varying_known_reals=[\"time_idx\"],\n",
        "        time_varying_unknown_reals=[\"Gls\", \"Ast\", \"xG\", \"xAG\", \"PrgC\", \"PrgP\", \"PrgR\", \"Tkl\", \"Int\", \"Blocks\", \"Performance_Index\", \"Future_Potential\"],\n",
        "        add_relative_time_idx=True,\n",
        "        add_target_scales=True,\n",
        "        add_encoder_length=True,\n",
        "        allow_missing_timesteps=True\n",
        "    )\n",
        "\n",
        "    return training"
      ],
      "metadata": {
        "id": "kh3XCcSXrPVd"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NBeatsLightningModule(LightningModule):\n",
        "    def __init__(self, nbeats_model):\n",
        "        super().__init__()\n",
        "        self.model = nbeats_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.model(x)  # N-BEATS output is directly the prediction\n",
        "        if isinstance(y, tuple):\n",
        "            y = y[0]\n",
        "        y = y.squeeze()\n",
        "        # Ensure y_hat and y have the same shape\n",
        "        y_hat = y_hat.view(y.shape)\n",
        "        loss = torchmetrics.functional.mean_squared_error(y_hat, y)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.model(x)\n",
        "        if isinstance(y, tuple):\n",
        "            y = y[0]\n",
        "        y = y.squeeze()\n",
        "        y_hat = y_hat.view(y.shape)\n",
        "        loss = torchmetrics.functional.mean_squared_error(y_hat, y)\n",
        "        self.log(\"val_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.03)"
      ],
      "metadata": {
        "id": "vsKjH7CJtGwf"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train N-BEATS model\n",
        "def train_nbeats(training, model=None):\n",
        "    trainer = Trainer(accelerator=\"cpu\", max_epochs=10)\n",
        "\n",
        "    if model is None:\n",
        "        nbeats = NBeats.from_dataset(\n",
        "            training,\n",
        "            learning_rate=0.03,\n",
        "            # ... other N-BEATS hyperparameters ...\n",
        "            loss=torchmetrics.MeanSquaredError(),\n",
        "        )\n",
        "        model = NBeatsLightningModule(nbeats)\n",
        "    else:\n",
        "        model.model.train()\n",
        "\n",
        "    trainer.fit(model, train_dataloaders=training.to_dataloader(train=True, batch_size=64))\n",
        "    return model"
      ],
      "metadata": {
        "id": "W0h0pxM0tMym"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate N-BEATS model\n",
        "def evaluate_nbeats(model, test_dataloader, df_test):\n",
        "    raw_predictions = model.model.predict(test_dataloader, mode=\"prediction\", return_x=True)\n",
        "    predictions = raw_predictions.cpu().detach().numpy()  # N-BEATS output is directly the prediction\n",
        "\n",
        "    # Reshape if necessary\n",
        "    predictions = predictions.reshape(-1)\n",
        "\n",
        "    if len(predictions) != len(df_test['G+A']):\n",
        "        predictions = np.repeat(predictions, len(df_test['G+A']) // len(predictions) + 1)\n",
        "        predictions = predictions[:len(df_test['G+A'])]\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "ptj-q3tGtQT7"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_metrics(predictions, actual):\n",
        "    mse = mean_squared_error(actual, predictions)\n",
        "    r2 = r2_score(actual, predictions)\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"R-squared (R2): {r2:.4f}\")\n",
        "    best_threshold = 0.5\n",
        "\n",
        "    predicted_labels = (predictions > best_threshold).astype(int)\n",
        "    actual_labels = (actual > best_threshold).astype(int)\n",
        "\n",
        "    f1 = f1_score(actual_labels, predicted_labels)\n",
        "    testing_accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    # print(f\"Training Accuracy: {training_accuracy:.4f}\")\n",
        "    print(f\"Testing Accuracy: {testing_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "XcxRSvQ-tTOb"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for hyperparameter optimization\n",
        "def objective(trial):\n",
        "    # Define hyperparameter search space for N-BEATS\n",
        "    params = {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True),\n",
        "        # ... other N-BEATS hyperparameters ...\n",
        "    }\n",
        "\n",
        "    # Create and train the model with the current hyperparameters\n",
        "    nbeats = NBeats.from_dataset(\n",
        "        training_initial,\n",
        "        **params,\n",
        "        loss=torchmetrics.MeanSquaredError(),\n",
        "    )\n",
        "    model = NBeatsLightningModule(nbeats)\n",
        "    trainer = Trainer(accelerator=\"cpu\", max_epochs=10)\n",
        "    trainer.fit(\n",
        "        model,\n",
        "        train_dataloaders=training_initial.to_dataloader(train=True, batch_size=64),\n",
        "        val_dataloaders=validation_data.to_dataloader(train=False, batch_size=64)\n",
        "    )\n",
        "\n",
        "    # Get validation loss\n",
        "    validation_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
        "\n",
        "    return validation_loss"
      ],
      "metadata": {
        "id": "Q_fNXhWptWod"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main workflow\n",
        "def main():\n",
        "    df_20_21, df_21_22, df_22_23, df_23_24, df_24_25 = load_data()\n",
        "\n",
        "    df_train = pd.concat([df_20_21, df_21_22, df_22_23, df_23_24])\n",
        "    df_test = df_24_25\n",
        "\n",
        "    # Identify players not in training data but in test data\n",
        "    players_in_test_not_in_train = set(df_test['Player'].unique()) - set(df_train['Player'].unique())\n",
        "\n",
        "    # Move data for these players from test to training\n",
        "    df_train = pd.concat([df_train, df_test[df_test['Player'].isin(players_in_test_not_in_train)]])\n",
        "    df_test = df_test[~df_test['Player'].isin(players_in_test_not_in_train)]  # Remove from test set\n",
        "\n",
        "    global training_initial  # Make training_initial accessible to objective function\n",
        "    training_initial = create_tft_dataset(df_train)\n",
        "\n",
        "    # Create validation data using subset instead of split method\n",
        "    global validation_data  # Make validation_data accessible to objective function\n",
        "    split_index = int(len(training_initial.data[\"time\"]) * 0.8)  # Use the length of the 'time' data\n",
        "\n",
        "    # Split the dataset using the underlying PyTorch tensors\n",
        "    training_initial_data = training_initial.data\n",
        "    validation_data_data = {}\n",
        "    for key in training_initial_data:\n",
        "        # Check if the value is a PyTorch tensor before cloning\n",
        "        if isinstance(training_initial_data[key], torch.Tensor):\n",
        "            validation_data_data[key] = training_initial_data[key][split_index:].clone()\n",
        "            training_initial_data[key] = training_initial_data[key][:split_index].clone()\n",
        "        # If it's a list, create a copy instead of cloning\n",
        "        elif isinstance(training_initial_data[key], list):\n",
        "            validation_data_data[key] = training_initial_data[key][split_index:]\n",
        "            training_initial_data[key] = training_initial_data[key][:split_index]\n",
        "        else:\n",
        "            # Handle other data types if necessary\n",
        "            validation_data_data[key] = training_initial_data[key]\n",
        "\n",
        "    # Update the data attributes of training_initial and validation_data\n",
        "    training_initial.data = training_initial_data\n",
        "    validation_data = TimeSeriesDataSet.from_dataset(training_initial, data=validation_data_data)\n",
        "\n",
        "    # Hyperparameter optimization using Optuna\n",
        "    study = optuna.create_study(direction=\"minimize\")  # Minimize validation loss\n",
        "    study.optimize(objective, n_trials=50)  # Run 50 trials\n",
        "\n",
        "    # Get the best hyperparameters\n",
        "    best_params = study.best_params\n",
        "\n",
        "    # Create and train the final N-BEATS model with the best hyperparameters\n",
        "    nbeats = NBeats.from_dataset(\n",
        "        training_initial,\n",
        "        **best_params,\n",
        "        loss=torchmetrics.MeanSquaredError(),\n",
        "    )\n",
        "    model = NBeatsLightningModule(nbeats)\n",
        "    trainer = Trainer(accelerator=\"cpu\", max_epochs=20)  # Increase epochs for final training\n",
        "    trainer.fit(model, train_dataloaders=training_initial.to_dataloader(train=True, batch_size=64))\n",
        "\n",
        "    # Now loop through remaining players in the test set for evaluation and retraining\n",
        "    for player_name in df_test['Player'].unique():\n",
        "        df_player_test = df_test[df_test['Player'] == player_name]\n",
        "\n",
        "        # Create a TimeSeriesDataSet for the current player\n",
        "        testing_player = create_tft_dataset(df_player_test)\n",
        "        test_dataloader_player = testing_player.to_dataloader(train=False, batch_size=64)\n",
        "\n",
        "        # Make predictions for the current player using evaluate_nbeats\n",
        "        predictions = evaluate_nbeats(model, test_dataloader_player, df_player_test)\n",
        "        actual = df_player_test['G+A'].values\n",
        "\n",
        "        display_metrics(predictions, actual)\n",
        "\n",
        "        # Retrain the model with the new data (optional - you might remove this)\n",
        "        # ... (Code for retraining if desired) ...\n",
        "\n",
        "        print(\"-\" * 20)  # Separator for each player's results\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save(model.model.state_dict(), \"nbeats_model_final.pth\")  # Save N-BEATS model\n",
        "\n",
        "    print(\"Final model saved as nbeats_model_final.pth\")"
      ],
      "metadata": {
        "id": "r3fqe3ahtadS"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the workflow\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "zYzlWS_CtuxP",
        "outputId": "68a68214-ff7f-409e-c712-e5aadbc77904"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py:1301: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 1245 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__Player': 'Aaron Cresswell'}, {'__group_id__Player': 'Aaron Hickey'}, {'__group_id__Player': 'Aaron Ramsey'}, {'__group_id__Player': 'Abde Ezzalzouli'}, {'__group_id__Player': 'Abdelhamid Sabiri'}, {'__group_id__Player': 'Abdou Harroui'}, {'__group_id__Player': 'Abdoulaye Bamba'}, {'__group_id__Player': 'Abdoulaye Doucouré'}, {'__group_id__Player': 'Abdoulaye Touré'}, {'__group_id__Player': 'Achraf Hakimi'}]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'time_idx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-4305aa581d7c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execute the workflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-109-10129c839748>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Update the data attributes of training_initial and validation_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mtraining_initial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_initial_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSeriesDataSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Hyperparameter optimization using Optuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36mfrom_dataset\u001b[0;34m(cls, dataset, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0mTimeSeriesDataSet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \"\"\"\n\u001b[0;32m-> 1174\u001b[0;31m         return cls.from_parameters(\n\u001b[0m\u001b[1;32m   1175\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_randomization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_randomization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mupdate_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36mfrom_parameters\u001b[0;34m(cls, parameters, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_forecasting/data/timeseries.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_prediction_length\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min prediction length must be larger than 0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_prediction_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min prediction length must be integer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Timeseries index should be of type integer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'time_idx'"
          ]
        }
      ]
    }
  ]
}